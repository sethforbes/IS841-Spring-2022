# Learning Goals

- Unsupervised ML Part 2 - Clustering and Dimensionality Reduction
- Review how to cluster our data and reduce features for downstream modeling
- Round out the lego pieces that we can assemble to fit our models

Slides:  https://docs.google.com/presentation/d/1JcThXWcYaHc9_ebOZhaeTc3gfi-7cwV5JV2o-X6dB6Y/edit?usp=sharing


## Unsupervised ML - Clustering and Segmentation

> NOTE:  Please install the Operator Toolbox Extension if you haven't already for the caching operator.

- [Notebook to demonstrate distances](https://docs.google.com/spreadsheets/d/1h0XTvPbGlmYkKuEdFvX0AD96Yv8So4elnBRY4pCepwc/edit?usp=sharing)
- KMeans - We define the clusters based on K.  This will introduce our ability to interate through a solution space.
- Hierarchical Clulstering (Agglomerative) - Bottom-up approach, clusters all records and we determine what is the correct number of clusters for our problem
- DBSCAN - Can determine outliers but requires my tuning (not as clear cut as Kmeans and HClust)

## Dimensionality Reduction - PCA

- PCA to reduce our features in order to create new attributes for downstream tasks
- Evaluation of how many components to retain
- Discuss TSNE as a non-linear alternative to PCA along with the tradeoffs in performance.

## Dedicated Team Work

- Time to meet in class as a team

